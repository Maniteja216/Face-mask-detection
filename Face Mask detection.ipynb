{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\Maniteja\\\\Downloads\\\\archive (1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"C:\\\\Users\\\\Maniteja\\\\Downloads\\\\archive (1)\\\\Medical mask\\\\Medical mask\\\\Medical Mask\\\\annotations\"\n",
    "image_directory = \"C:\\\\Users\\\\Maniteja\\\\Downloads\\\\archive (1)\\\\Medical mask\\\\Medical mask\\\\Medical Mask\\\\images\"\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating two helper functions\n",
    "cvNet = cv2.dnn.readNetFromCaffe('weights.caffemodel')\n",
    "def getJSON(filePathandName):\n",
    "    with open(filePathandName,'r') as f:\n",
    "        return json.load(f)\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)])\n",
    "    return cv2.LUT(image.astype(np.uint8), table.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FileName': '1801.jpg',\n",
       " 'NumOfAnno': 1,\n",
       " 'Annotations': [{'isProtected': False,\n",
       "   'ID': 924868908868875136,\n",
       "   'BoundingBox': [451, 186, 895, 697],\n",
       "   'classname': 'face_no_mask',\n",
       "   'Confidence': 1,\n",
       "   'Attributes': {}}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore the JSON data provided for the training\n",
    "jsonfiles= []\n",
    "for i in os.listdir(directory):\n",
    "    jsonfiles.append(getJSON(os.path.join(directory,i)))\n",
    "jsonfiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>classname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2756.png</td>\n",
       "      <td>69</td>\n",
       "      <td>126</td>\n",
       "      <td>294</td>\n",
       "      <td>392</td>\n",
       "      <td>face_with_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2756.png</td>\n",
       "      <td>505</td>\n",
       "      <td>10</td>\n",
       "      <td>723</td>\n",
       "      <td>283</td>\n",
       "      <td>face_with_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2756.png</td>\n",
       "      <td>75</td>\n",
       "      <td>252</td>\n",
       "      <td>264</td>\n",
       "      <td>390</td>\n",
       "      <td>mask_colorful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2756.png</td>\n",
       "      <td>521</td>\n",
       "      <td>136</td>\n",
       "      <td>711</td>\n",
       "      <td>277</td>\n",
       "      <td>mask_colorful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6098.jpg</td>\n",
       "      <td>360</td>\n",
       "      <td>85</td>\n",
       "      <td>728</td>\n",
       "      <td>653</td>\n",
       "      <td>face_no_mask</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name   x1   x2   y1   y2       classname\n",
       "0  2756.png   69  126  294  392  face_with_mask\n",
       "1  2756.png  505   10  723  283  face_with_mask\n",
       "2  2756.png   75  252  264  390   mask_colorful\n",
       "3  2756.png  521  136  711  277   mask_colorful\n",
       "4  6098.jpg  360   85  728  653    face_no_mask"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "data = []\n",
    "img_size = 124\n",
    "mask = ['face_with_mask']\n",
    "non_mask = [\"face_no_mask\"]\n",
    "labels={'mask':0,'without mask':1}\n",
    "for i in df[\"name\"].unique():\n",
    "    f = i+\".json\"\n",
    "    for j in getJSON(os.path.join(directory,f)).get(\"Annotations\"):\n",
    "        if j[\"classname\"] in mask:\n",
    "            x,y,w,h = j[\"BoundingBox\"]\n",
    "            img = cv2.imread(os.path.join(image_directory,i),1)\n",
    "            img = img[y:h,x:w]\n",
    "            img = cv2.resize(img,(img_size,img_size))\n",
    "            data.append([img,labels[\"mask\"]])\n",
    "        if j[\"classname\"] in non_mask:\n",
    "            x,y,w,h = j[\"BoundingBox\"]\n",
    "            img = cv2.imread(os.path.join(image_directory,i),1)\n",
    "            img = img[y:h,x:w]\n",
    "            img = cv2.resize(img,(img_size,img_size))    \n",
    "            data.append([img,labels[\"without mask\"]])\n",
    "random.shuffle(data)\n",
    "\n",
    "p = []\n",
    "for face in data:\n",
    "    if(face[1] == 0):\n",
    "        p.append(\"Mask\")\n",
    "    else:\n",
    "        p.append(\"No Mask\")\n",
    "sns.countplot(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the data before training a neural network\n",
    "X = []\n",
    "Y = []\n",
    "for features,label in data:\n",
    "    X.append(features)\n",
    "    Y.append(label)\n",
    "\n",
    "X = np.array(X)/255.0\n",
    "X = X.reshape(-1,124,124,3)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maniteja\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "143/143 [==============================] - 952s 7s/step - loss: 0.7135 - accuracy: 0.7892 - val_loss: 0.2524 - val_accuracy: 0.8974\n",
      "Epoch 2/5\n",
      "143/143 [==============================] - 899s 6s/step - loss: 0.2928 - accuracy: 0.8745 - val_loss: 0.2500 - val_accuracy: 0.9026\n",
      "Epoch 3/5\n",
      "143/143 [==============================] - 905s 6s/step - loss: 0.2685 - accuracy: 0.8909 - val_loss: 0.2099 - val_accuracy: 0.9157\n",
      "Epoch 4/5\n",
      "143/143 [==============================] - 930s 7s/step - loss: 0.2812 - accuracy: 0.8831 - val_loss: 0.2480 - val_accuracy: 0.9043\n",
      "Epoch 5/5\n",
      "143/143 [==============================] - 878s 6s/step - loss: 0.2509 - accuracy: 0.9010 - val_loss: 0.1920 - val_accuracy: 0.9287\n"
     ]
    }
   ],
   "source": [
    "# Traing the neural networkfor facemask detection\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding = \"same\", activation='relu', input_shape=(124,124,3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam' ,metrics=['accuracy'])\n",
    "xtrain,xval,ytrain,yval=train_test_split(X, Y,train_size=0.8,random_state=0)\n",
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                             samplewise_center=False,  \n",
    "                             featurewise_std_normalization=False,  \n",
    "                             samplewise_std_normalization=False,  \n",
    "                             zca_whitening=False,    \n",
    "                             rotation_range=15,    \n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,  \n",
    "                             horizontal_flip=True,  \n",
    "                             vertical_flip=False)\n",
    "\n",
    "datagen.fit(xtrain)\n",
    "\n",
    "history = model.fit_generator(datagen.flow(xtrain, ytrain, batch_size=32),\n",
    "                    steps_per_epoch=xtrain.shape[0]//32,\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_data=(xval, yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "test_images = ['1114.png','1504.jpg', '0072.jpg','0012.jpg','0353.jpg','1374.jpg']\n",
    "\n",
    "gamma = 2.0\n",
    "fig = plt.figure(figsize = (14,14))\n",
    "rows = 3\n",
    "cols = 2\n",
    "axes = []\n",
    "assign = {'0':'Mask','1':\"No Mask\"}\n",
    "for j,im in enumerate(test_images):\n",
    "    image =  cv2.imread(os.path.join(image_directory,im),1)\n",
    "    image =  adjust_gamma(image, gamma=gamma)\n",
    "    (h, w) = image.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300,300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    cvNet.setInput(blob)\n",
    "    detections = cvNet.forward()\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        try:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            frame = image[startY:endY, startX:endX]\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > 0.2:\n",
    "                im = cv2.resize(frame,(img_size,img_size))\n",
    "                im = np.array(im)/255.0\n",
    "                im = im.reshape(1,124,124,3)\n",
    "                result = model.predict(im)\n",
    "                if result>0.5:\n",
    "                    label_Y = 1\n",
    "                else:\n",
    "                    label_Y = 0\n",
    "                cv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
    "                cv2.putText(image,assign[str(label_Y)] , (startX, startY-10), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (36,255,12), 2)\n",
    "        \n",
    "        except:pass\n",
    "    axes.append(fig.add_subplot(rows, cols, j+1))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
